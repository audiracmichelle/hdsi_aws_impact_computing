# Welcome to HDSI AWS Impact Computing
Let's create applications centered compute solutions for social impact.

### 1. Data Infrastructure

The computing and storage backbone that supports your research.

Examples: AWS S3 buckets, databases, Redshift, or Weka-backed high-performance storage used by Harvard clusters.

Includes access patterns, versioning, and cloud orchestration.

### 2. Data Pipelines & Processing

Automated workflows for ingesting, cleaning, transforming, and harmonizing data from multiple sources.

Often modular and reproducible â€” e.g., Python workflows, Airflow, or AWS Step Functions connecting compute and storage.

### 3. Data Standards & Metadata

Consistent naming, units, and documentation so data is discoverable and reusable.

Think of schema definitions, metadata registries, or FAIR (Findable, Accessible, Interoperable, Reusable) principles.

### 4. Analytical & Machine Learning Layers

The models and algorithms that consume processed data:

Predictive models, simulations, or foundation models.

This layer can include APIs for inference or exploratory notebooks.

### 5. Access, Collaboration, and Reuse

The interfaces that let others interact with the data or model:

APIs, dashboards, data catalogs, or repositories.


